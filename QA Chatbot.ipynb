{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_qa.txt', 'rb') as f:\n",
    "    train_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "(['Mary', 'moved', 'to', 'the', 'bathroom', '.', 'Sandra', 'journeyed', 'to', 'the', 'bedroom', '.', 'Mary', 'went', 'back', 'to', 'the', 'bedroom', '.', 'Daniel', 'went', 'back', 'to', 'the', 'hallway', '.'], ['Is', 'Daniel', 'in', 'the', 'bathroom', '?'], 'no')\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data[1])) # each training data consist of a Story Question Answer therefore length of every example is 3\n",
    "print(train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom . Mary went back to the bedroom . Daniel went back to the hallway . Sandra went to the kitchen . Daniel went back to the bathroom .'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=' '.join(train_data[2][0])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Daniel in the office ?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[2][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "for story, question, answer in train_data:\n",
    "    vocab = vocab.union(set(story)) #Set returns unique words in the sentence\n",
    "                                    #Union returns the unique common elements from a two sets\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('yes')\n",
    "vocab.add('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len=len(vocab)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_story_len = []\n",
    "li_ques_len = []\n",
    "for i in range(len(train_data)):\n",
    "    \n",
    "    story_len = 0\n",
    "    story_len = len(train_data[i][0])\n",
    "    li_story_len.append(story_len)\n",
    "    \n",
    "    ques_len = 0\n",
    "    ques_len = len(train_data[i][1])\n",
    "    li_ques_len.append(ques_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max story len =  156\n",
      "max ques len =  6\n"
     ]
    }
   ],
   "source": [
    "max_story_len = max(li_story_len)\n",
    "max_ques_len = max(li_ques_len)\n",
    "print(\"max story len = \",max_story_len)\n",
    "print(\"max ques len = \",max_ques_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mary': 1, 'office': 2, 'the': 3, 'bathroom': 4, 'left': 5, 'picked': 6, 'took': 7, 'journeyed': 8, 'yes': 9, 'bedroom': 10, 'to': 11, 'hallway': 12, 'is': 13, 'there': 14, 'john': 15, 'put': 16, 'up': 17, 'dropped': 18, 'no': 19, 'down': 20, 'milk': 21, 'daniel': 22, 'travelled': 23, '?': 24, 'discarded': 25, 'sandra': 26, 'in': 27, '.': 28, 'football': 29, 'garden': 30, 'apple': 31, 'kitchen': 32, 'moved': 33, 'got': 34, 'grabbed': 35, 'back': 36, 'went': 37}\n"
     ]
    }
   ],
   "source": [
    "tokenizer=Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)\n",
    "word_index=tokenizer.word_index\n",
    "print(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories=[]\n",
    "questions=[]\n",
    "answers=[]\n",
    "for i in range(len(train_data)):\n",
    "    \n",
    "    story_sequences = tokenizer.texts_to_sequences(train_data[i][0])\n",
    "    story=[]\n",
    "    for ele in story_sequences:\n",
    "        story.extend(ele)\n",
    "    stories.append(story)\n",
    "    \n",
    "    ques_sequences = tokenizer.texts_to_sequences(train_data[i][1])\n",
    "    ques=[]\n",
    "    for ele in ques_sequences:\n",
    "        ques.extend(ele)\n",
    "    questions.append(ques)\n",
    "    \n",
    "    ans = np.zeros(len(word_index)+1) #Index 0 Reserved when padding the sequences\n",
    "    ans[word_index[train_data[i][2]]] = 1\n",
    "    answers.append(ans)\n",
    "\n",
    "X_story = pad_sequences(stories, maxlen=max_story_len)\n",
    "X_ques = pad_sequences(questions, maxlen=max_ques_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 38)\n"
     ]
    }
   ],
   "source": [
    "X_ans=np.asarray(answers)\n",
    "print(X_ans.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 156)\n",
      "(10000, 6)\n",
      "(10000, 38)\n"
     ]
    }
   ],
   "source": [
    "print(X_story.shape)\n",
    "print(X_ques.shape)\n",
    "print(X_ans.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout, add, dot, concatenate, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(max_story_len,max_ques_len,vocab_len):\n",
    "    \n",
    "    story = Input((max_story_len,))\n",
    "    ques = Input((max_ques_len,))\n",
    "    \n",
    "    input_encoder_m = Sequential()\n",
    "    input_encoder_m.add(Embedding(input_dim=vocab_len, output_dim=64))\n",
    "    input_encoder_m.add(Dropout(0.3))\n",
    "    \n",
    "    input_encoder_c = Sequential()\n",
    "    input_encoder_c.add(Embedding(input_dim=vocab_len, output_dim=max_ques_len))\n",
    "    input_encoder_c.add(Dropout(0.3))\n",
    "    \n",
    "    ques_encoder = Sequential()\n",
    "    ques_encoder.add(Embedding(input_dim=vocab_len, output_dim=64, input_length=max_ques_len))\n",
    "    ques_encoder.add(Dropout(0.3))\n",
    "    \n",
    "    input_encoded_m = input_encoder_m(story)\n",
    "    input_encoded_c = input_encoder_c(story)\n",
    "    ques_encoded = ques_encoder(ques)\n",
    "    \n",
    "    match=dot([input_encoded_m,ques_encoded],axes=(2,2))\n",
    "    match=Activation('softmax')(match)\n",
    "    \n",
    "    response = add([match,input_encoded_c])\n",
    "    response = Permute((2,1))(response)\n",
    "    \n",
    "    answer = concatenate([response,ques_encoded])\n",
    "    answer = LSTM(32)(answer)\n",
    "    answer = Dropout(0.5)(answer)\n",
    "    answer = Dense(vocab_len)(answer)\n",
    "    answer = Activation('softmax')(answer)\n",
    "    \n",
    "    model = Model([story,ques],answer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model(max_story_len, max_ques_len,vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_26 (Sequential)      multiple             2432        input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sequential_28 (Sequential)      (None, 6, 64)        2432        input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot_8 (Dot)                     (None, 156, 6)       0           sequential_26[1][0]              \n",
      "                                                                 sequential_28[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 156, 6)       0           dot_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_27 (Sequential)      multiple             228         input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 156, 6)       0           activation_11[0][0]              \n",
      "                                                                 sequential_27[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "permute_6 (Permute)             (None, 6, 156)       0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 6, 220)       0           permute_6[0][0]                  \n",
      "                                                                 sequential_28[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   (None, 32)           32384       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 32)           0           lstm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 38)           1254        dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 38)           0           dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 3s 411us/step - loss: 0.8891 - accuracy: 0.4974 - val_loss: 0.7005 - val_accuracy: 0.4960\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 3s 329us/step - loss: 0.7057 - accuracy: 0.5035 - val_loss: 0.6947 - val_accuracy: 0.4960\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 3s 334us/step - loss: 0.6962 - accuracy: 0.5035 - val_loss: 0.6931 - val_accuracy: 0.5040\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 3s 348us/step - loss: 0.6948 - accuracy: 0.4979 - val_loss: 0.6935 - val_accuracy: 0.5040\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 3s 346us/step - loss: 0.6950 - accuracy: 0.4991 - val_loss: 0.6939 - val_accuracy: 0.4960\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 3s 359us/step - loss: 0.6952 - accuracy: 0.4996 - val_loss: 0.6938 - val_accuracy: 0.5040\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 3s 359us/step - loss: 0.6943 - accuracy: 0.5021 - val_loss: 0.6943 - val_accuracy: 0.4960\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 3s 355us/step - loss: 0.6948 - accuracy: 0.5017 - val_loss: 0.6935 - val_accuracy: 0.4960\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 3s 329us/step - loss: 0.6947 - accuracy: 0.4952 - val_loss: 0.6945 - val_accuracy: 0.4960\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 3s 338us/step - loss: 0.6944 - accuracy: 0.4961 - val_loss: 0.6955 - val_accuracy: 0.4960\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 3s 336us/step - loss: 0.6938 - accuracy: 0.5086 - val_loss: 0.6988 - val_accuracy: 0.4960\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 3s 396us/step - loss: 0.6942 - accuracy: 0.5023 - val_loss: 0.6929 - val_accuracy: 0.5120\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 3s 332us/step - loss: 0.6935 - accuracy: 0.5076 - val_loss: 0.6920 - val_accuracy: 0.5150\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 3s 329us/step - loss: 0.6908 - accuracy: 0.5265 - val_loss: 0.6880 - val_accuracy: 0.5245\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 3s 328us/step - loss: 0.6822 - accuracy: 0.5506 - val_loss: 0.6696 - val_accuracy: 0.5980\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 3s 360us/step - loss: 0.6530 - accuracy: 0.6194 - val_loss: 0.6182 - val_accuracy: 0.6710\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 3s 344us/step - loss: 0.6216 - accuracy: 0.6603 - val_loss: 0.5913 - val_accuracy: 0.6815\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 3s 335us/step - loss: 0.6008 - accuracy: 0.6839 - val_loss: 0.5722 - val_accuracy: 0.6995\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 3s 358us/step - loss: 0.5748 - accuracy: 0.6996 - val_loss: 0.5336 - val_accuracy: 0.7365\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 3s 343us/step - loss: 0.5551 - accuracy: 0.7275 - val_loss: 0.5061 - val_accuracy: 0.7585\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 3s 337us/step - loss: 0.5215 - accuracy: 0.7515 - val_loss: 0.4818 - val_accuracy: 0.7815\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 3s 361us/step - loss: 0.4989 - accuracy: 0.7757 - val_loss: 0.4460 - val_accuracy: 0.8120\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 3s 338us/step - loss: 0.4722 - accuracy: 0.7944 - val_loss: 0.4238 - val_accuracy: 0.8135\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 3s 332us/step - loss: 0.4553 - accuracy: 0.7981 - val_loss: 0.4135 - val_accuracy: 0.8185\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 3s 339us/step - loss: 0.4296 - accuracy: 0.8207 - val_loss: 0.4180 - val_accuracy: 0.8335\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 3s 332us/step - loss: 0.4293 - accuracy: 0.8216 - val_loss: 0.3860 - val_accuracy: 0.8350\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 3s 341us/step - loss: 0.4090 - accuracy: 0.8319 - val_loss: 0.3832 - val_accuracy: 0.8335\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 3s 369us/step - loss: 0.4012 - accuracy: 0.8307 - val_loss: 0.3812 - val_accuracy: 0.8265\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 3s 338us/step - loss: 0.3921 - accuracy: 0.8357 - val_loss: 0.3679 - val_accuracy: 0.8430\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 3s 334us/step - loss: 0.3807 - accuracy: 0.8438 - val_loss: 0.3682 - val_accuracy: 0.8490\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 3s 340us/step - loss: 0.3748 - accuracy: 0.8425 - val_loss: 0.3648 - val_accuracy: 0.8395\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 3s 348us/step - loss: 0.3710 - accuracy: 0.8451 - val_loss: 0.3675 - val_accuracy: 0.8545\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 3s 358us/step - loss: 0.3627 - accuracy: 0.8514 - val_loss: 0.3617 - val_accuracy: 0.8375\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 3s 356us/step - loss: 0.3643 - accuracy: 0.8514 - val_loss: 0.3602 - val_accuracy: 0.8495\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 3s 359us/step - loss: 0.3636 - accuracy: 0.8510 - val_loss: 0.3620 - val_accuracy: 0.8535\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 3s 381us/step - loss: 0.3495 - accuracy: 0.8561 - val_loss: 0.3636 - val_accuracy: 0.8455\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 3s 370us/step - loss: 0.3490 - accuracy: 0.8565 - val_loss: 0.3561 - val_accuracy: 0.8545\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 3s 364us/step - loss: 0.3486 - accuracy: 0.8555 - val_loss: 0.3592 - val_accuracy: 0.8585\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 3s 397us/step - loss: 0.3372 - accuracy: 0.8626 - val_loss: 0.3511 - val_accuracy: 0.8520\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 3s 353us/step - loss: 0.3374 - accuracy: 0.8612 - val_loss: 0.3540 - val_accuracy: 0.8535\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 3s 350us/step - loss: 0.3339 - accuracy: 0.8627 - val_loss: 0.3557 - val_accuracy: 0.8435\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 3s 348us/step - loss: 0.3337 - accuracy: 0.8618 - val_loss: 0.3552 - val_accuracy: 0.8505\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 3s 356us/step - loss: 0.3269 - accuracy: 0.8674 - val_loss: 0.3602 - val_accuracy: 0.8340\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 3s 356us/step - loss: 0.3310 - accuracy: 0.8651 - val_loss: 0.3518 - val_accuracy: 0.8450\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 3s 354us/step - loss: 0.3247 - accuracy: 0.8644 - val_loss: 0.3493 - val_accuracy: 0.8445\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 3s 335us/step - loss: 0.3221 - accuracy: 0.8702 - val_loss: 0.3634 - val_accuracy: 0.8535\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 3s 336us/step - loss: 0.3211 - accuracy: 0.8700 - val_loss: 0.3430 - val_accuracy: 0.8510\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 3s 356us/step - loss: 0.3179 - accuracy: 0.8690 - val_loss: 0.3510 - val_accuracy: 0.8470\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 3s 345us/step - loss: 0.3142 - accuracy: 0.8706 - val_loss: 0.3657 - val_accuracy: 0.8470\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 3s 356us/step - loss: 0.3113 - accuracy: 0.8723 - val_loss: 0.3472 - val_accuracy: 0.8470\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 3s 357us/step - loss: 0.3128 - accuracy: 0.8717 - val_loss: 0.3506 - val_accuracy: 0.8480\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 3s 335us/step - loss: 0.3067 - accuracy: 0.8706 - val_loss: 0.3516 - val_accuracy: 0.8510\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 3s 337us/step - loss: 0.3052 - accuracy: 0.8751 - val_loss: 0.3606 - val_accuracy: 0.8435\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 3s 390us/step - loss: 0.3026 - accuracy: 0.8730 - val_loss: 0.3544 - val_accuracy: 0.8475\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 3s 385us/step - loss: 0.3006 - accuracy: 0.8745 - val_loss: 0.3551 - val_accuracy: 0.8470\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 3s 392us/step - loss: 0.2971 - accuracy: 0.8764 - val_loss: 0.3553 - val_accuracy: 0.8445\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 3s 351us/step - loss: 0.2954 - accuracy: 0.8754 - val_loss: 0.3529 - val_accuracy: 0.8420\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 3s 384us/step - loss: 0.2907 - accuracy: 0.8767 - val_loss: 0.3612 - val_accuracy: 0.8405\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 3s 364us/step - loss: 0.2954 - accuracy: 0.8775 - val_loss: 0.3555 - val_accuracy: 0.8440\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 3s 397us/step - loss: 0.2875 - accuracy: 0.8808 - val_loss: 0.3614 - val_accuracy: 0.8470\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 3s 407us/step - loss: 0.2846 - accuracy: 0.8838 - val_loss: 0.3692 - val_accuracy: 0.8400\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 3s 407us/step - loss: 0.2805 - accuracy: 0.8831 - val_loss: 0.3854 - val_accuracy: 0.8315\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 3s 385us/step - loss: 0.2778 - accuracy: 0.8839 - val_loss: 0.3532 - val_accuracy: 0.8445\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 3s 402us/step - loss: 0.2814 - accuracy: 0.8836 - val_loss: 0.3624 - val_accuracy: 0.8440\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 3s 374us/step - loss: 0.2759 - accuracy: 0.8820 - val_loss: 0.3699 - val_accuracy: 0.8505\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 3s 399us/step - loss: 0.2738 - accuracy: 0.8860 - val_loss: 0.3638 - val_accuracy: 0.8485\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 3s 401us/step - loss: 0.2739 - accuracy: 0.8878 - val_loss: 0.3683 - val_accuracy: 0.8440\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 3s 380us/step - loss: 0.2709 - accuracy: 0.8878 - val_loss: 0.3750 - val_accuracy: 0.8485\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 3s 368us/step - loss: 0.2669 - accuracy: 0.8900 - val_loss: 0.3832 - val_accuracy: 0.8440\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 3s 350us/step - loss: 0.2647 - accuracy: 0.8915 - val_loss: 0.3792 - val_accuracy: 0.8445\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 3s 373us/step - loss: 0.2672 - accuracy: 0.8898 - val_loss: 0.3717 - val_accuracy: 0.8440\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 3s 382us/step - loss: 0.2643 - accuracy: 0.8878 - val_loss: 0.3796 - val_accuracy: 0.8495\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 3s 352us/step - loss: 0.2602 - accuracy: 0.8924 - val_loss: 0.3810 - val_accuracy: 0.8400\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 3s 359us/step - loss: 0.2646 - accuracy: 0.8940 - val_loss: 0.3887 - val_accuracy: 0.8405\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 3s 386us/step - loss: 0.2589 - accuracy: 0.8941 - val_loss: 0.4278 - val_accuracy: 0.8295\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 3s 328us/step - loss: 0.2531 - accuracy: 0.8967 - val_loss: 0.3990 - val_accuracy: 0.8440\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 3s 406us/step - loss: 0.2457 - accuracy: 0.8986 - val_loss: 0.3974 - val_accuracy: 0.8360\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 3s 332us/step - loss: 0.2514 - accuracy: 0.8957 - val_loss: 0.3916 - val_accuracy: 0.8380\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 3s 339us/step - loss: 0.2487 - accuracy: 0.8974 - val_loss: 0.3965 - val_accuracy: 0.8415\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 3s 332us/step - loss: 0.2514 - accuracy: 0.8978 - val_loss: 0.4178 - val_accuracy: 0.8285\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 3s 339us/step - loss: 0.2383 - accuracy: 0.9030 - val_loss: 0.4298 - val_accuracy: 0.8375\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 3s 328us/step - loss: 0.2428 - accuracy: 0.9034 - val_loss: 0.4350 - val_accuracy: 0.8240\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 3s 382us/step - loss: 0.2399 - accuracy: 0.9021 - val_loss: 0.4334 - val_accuracy: 0.8315\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 3s 337us/step - loss: 0.2343 - accuracy: 0.9051 - val_loss: 0.4078 - val_accuracy: 0.8435\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 3s 341us/step - loss: 0.2334 - accuracy: 0.9047 - val_loss: 0.4335 - val_accuracy: 0.8455\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 3s 337us/step - loss: 0.2327 - accuracy: 0.9036 - val_loss: 0.4234 - val_accuracy: 0.8360\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 3s 333us/step - loss: 0.2339 - accuracy: 0.9050 - val_loss: 0.4199 - val_accuracy: 0.8390\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 3s 359us/step - loss: 0.2299 - accuracy: 0.9065 - val_loss: 0.4231 - val_accuracy: 0.8445\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 3s 379us/step - loss: 0.2317 - accuracy: 0.9072 - val_loss: 0.4291 - val_accuracy: 0.8350\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 3s 349us/step - loss: 0.2263 - accuracy: 0.9053 - val_loss: 0.4366 - val_accuracy: 0.8340\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 3s 339us/step - loss: 0.2249 - accuracy: 0.9096 - val_loss: 0.4368 - val_accuracy: 0.8395\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 3s 388us/step - loss: 0.2242 - accuracy: 0.9080 - val_loss: 0.4264 - val_accuracy: 0.8365\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 3s 395us/step - loss: 0.2166 - accuracy: 0.9120 - val_loss: 0.4849 - val_accuracy: 0.8305\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 3s 388us/step - loss: 0.2139 - accuracy: 0.9134 - val_loss: 0.4390 - val_accuracy: 0.8405\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 3s 345us/step - loss: 0.2180 - accuracy: 0.9118 - val_loss: 0.4562 - val_accuracy: 0.8335\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 3s 349us/step - loss: 0.2135 - accuracy: 0.9164 - val_loss: 0.4720 - val_accuracy: 0.8310\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 3s 375us/step - loss: 0.2117 - accuracy: 0.9168 - val_loss: 0.4625 - val_accuracy: 0.8345\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 3s 360us/step - loss: 0.2179 - accuracy: 0.9110 - val_loss: 0.4490 - val_accuracy: 0.8295\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 3s 426us/step - loss: 0.2112 - accuracy: 0.9154 - val_loss: 0.4583 - val_accuracy: 0.8405\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 3s 433us/step - loss: 0.2117 - accuracy: 0.9140 - val_loss: 0.4506 - val_accuracy: 0.8330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1e8aa7fe688>"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X_story,X_ques],X_ans, batch_size = 32, epochs = 100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 83us/step\n"
     ]
    }
   ],
   "source": [
    "loss_train,acc_train = model.evaluate([X_story,X_ques],X_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20182947977781296\n",
      "0.9239000082015991\n"
     ]
    }
   ],
   "source": [
    "print(loss_train)\n",
    "print(acc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict([X_story, X_ques])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_story='sandra is in bathroom . sandra is in my bedroom . '\n",
    "random_ques='is sandra in my bedroom ?'\n",
    "data=[random_story.split(),random_ques.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories=[]\n",
    "questions=[]\n",
    "answers=[]\n",
    "story_sequences = tokenizer.texts_to_sequences(data[0])\n",
    "story=[]\n",
    "for ele in story_sequences:\n",
    "    story.extend(ele)\n",
    "stories.append(story)\n",
    "\n",
    "ques_sequences = tokenizer.texts_to_sequences(data[1])\n",
    "ques=[]\n",
    "for ele in ques_sequences:\n",
    "    ques.extend(ele)\n",
    "questions.append(ques)\n",
    "\n",
    "X_random_story = pad_sequences(stories, maxlen=max_story_len)\n",
    "X_random_ques = pad_sequences(questions, maxlen=max_ques_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 156)"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_random_story.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_random = model.predict([X_random_story, X_random_ques])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 38)"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_random.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0145969e-12, 1.1770227e-12, 1.0679633e-12, 1.1394003e-12,\n",
       "        1.1369321e-12, 1.1042479e-12, 1.1630371e-12, 1.1195896e-12,\n",
       "        1.2375035e-12, 9.5696414e-01, 1.0485562e-12, 1.1885166e-12,\n",
       "        1.0977924e-12, 1.2219249e-12, 1.1198971e-12, 1.1298781e-12,\n",
       "        1.0074755e-12, 1.1843144e-12, 1.0360477e-12, 4.3035887e-02,\n",
       "        1.0541169e-12, 1.2497096e-12, 1.2232845e-12, 1.2250426e-12,\n",
       "        1.1373984e-12, 1.0906401e-12, 1.1104786e-12, 1.1363511e-12,\n",
       "        1.0392182e-12, 1.0612826e-12, 1.1941816e-12, 1.2439973e-12,\n",
       "        1.0503338e-12, 1.1493294e-12, 1.1664249e-12, 1.2374304e-12,\n",
       "        9.9944456e-13, 1.0474629e-12]], dtype=float32)"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "for key,value in word_index.items() :\n",
    "    if word_index[key]==np.argmax(predictions_random):\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
